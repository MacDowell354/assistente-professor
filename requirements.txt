fastapi==0.95.1
uvicorn==0.20.0
jinja2==3.1.2
python-multipart==0.0.6
python-dotenv==1.0.0
passlib[bcrypt]==1.7.4
bcrypt==3.2.2
python-jose[cryptography]==3.3.0

# OpenAI Python >=1.1.0 para ser compatível com llama-index
openai==1.3.5

# O httpx precisa ser >=0.24 para aceitar proxies
httpx==0.24.1

# Llama-Index e seus sub-pacotes de LLM/embeddings
llama-index==0.10.30
llama-index-llms-openai==0.1.27
llama-index-embeddings-openai==0.1.11

# Vetorização local
faiss-cpu==1.7.3

typing-extensions==4.7.0

# Markdown para renderizar respostas
markdown2==2.4.10
