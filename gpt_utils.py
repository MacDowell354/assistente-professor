import os
from openai import OpenAI, OpenAIError

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("‚ùå Vari√°vel de ambiente OPENAI_API_KEY n√£o encontrada.")

client = OpenAI(api_key=api_key)

OUT_OF_SCOPE_MSG = (
    "Essa pergunta √© muito boa, mas no momento ela est√° <strong>fora do conte√∫do abordado nas aulas do curso Consult√≥rio High Ticket</strong>. "
    "Isso pode indicar uma oportunidade de melhoria do nosso material! üòä<br><br>"
    "Vamos sinalizar esse tema para a equipe pedag√≥gica avaliar a inclus√£o em vers√µes futuras do curso. "
    "Enquanto isso, recomendamos focar nos ensinamentos j√° dispon√≠veis para ter os melhores resultados poss√≠veis no consult√≥rio."
)

def generate_answer(
    question: str,
    context: str = "",
    history: str = None,
    tipo_de_prompt: str = "explicacao"
) -> str:
    termos_mensagem_auto = [
        "mensagem autom√°tica", "whatsapp", "resposta autom√°tica",
        "fim de semana", "fora do hor√°rio", "responder depois", "rob√¥"
    ]
    if any(t in question.lower() for t in termos_mensagem_auto):
        return (
            "Ol√°, querida! Vamos esclarecer isso com base no que a pr√≥pria Nanda orienta no curso:<br><br>"
            "üìå A Nanda n√£o recomenda o uso de <strong>mensagens autom√°ticas gen√©ricas</strong> no WhatsApp..."
        )

    # **Somente estes tipos exigem contexto**; os demais (incluindo 'capitacao_sem_marketing_digital' e 'health_plan')
    # usam o template mesmo sem context.
    tipos_que_exigem_contexto = {"explicacao", "faq", "revisao", "correcao", "precificacao"}
    if tipo_de_prompt in tipos_que_exigem_contexto and (not context or not context.strip()):
        return OUT_OF_SCOPE_MSG

    identidade = (
        "<strong>Voc√™ √© Nanda Mac.ia</strong>, a IA oficial da Nanda Mac, treinada com o conte√∫do do curso <strong>Consult√≥rio High Ticket</strong>.<br><br>"
    )

    prompt_variacoes = {
        "explicacao": "...",  # seus templates existentes
        "faq": "...",
        "revisao": "...",
        "aplicacao": "...",
        "correcao": "...",
        "capitacao_sem_marketing_digital": (
            "<strong>Contexto:</strong> O m√©todo da Nanda Mac <u>n√£o depende de redes sociais ou tr√°fego pago</u>. "
            "Explique como o aluno pode atrair pacientes de alto valor **sem usar Instagram ou an√∫ncios**..."
        ),
        "precificacao": "...",
        "health_plan": "..."  # seu template de Health Plan em ingl√™s
    }

    # Montagem do prompt
    prompt = identidade + prompt_variacoes.get(tipo_de_prompt, "")
    if context:
        prompt += f"<br><br><strong>üìö Contexto relevante do curso:</strong><br>{context}<br>"
    if history:
        prompt += f"<br><strong>üìú Hist√≥rico anterior:</strong><br>{history}<br>"
    prompt += f"<br><strong>ü§î Pergunta:</strong><br>{question}<br><br><strong>üß† Resposta:</strong><br>"

    modelo_escolhido = "gpt-4"
    try:
        response = client.chat.completions.create(
            model=modelo_escolhido,
            messages=[{"role": "user", "content": prompt}]
        )
    except OpenAIError:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )

    return response.choices[0].message.content
