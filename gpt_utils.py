import os
import re
import random
from openai import OpenAI, OpenAIError

TRANSCRIPTS_PATH = os.path.join(os.path.dirname(__file__), "transcricoes.txt")
client = OpenAI()

OUT_OF_SCOPE_MSG = (
    "Desculpe, ainda n√£o tenho informa√ß√µes suficientes sobre esse tema espec√≠fico do curso. "
    "Por favor, envie outra pergunta ou consulte o material da aula."
)

GREETINGS = [
    "Ol√°, Doutor(a), seja muito bem-vindo(a)!",
    "Oi, Doutor(a), tudo bem? Como posso ajudar?",
    "Bem-vindo(a) de volta, Doutor(a)!",
    "Ol√°, Doutor(a)! Estou aqui para apoiar voc√™ no seu crescimento"
]

CLOSINGS = [
    "Se quiser um exemplo pr√°tico ou modelo, clique nos bot√µes abaixo.",
    "Tem outro desafio no seu consult√≥rio? Me conte ou clique em Novo Tema.",
    "Se quiser aprofundar, escolha uma op√ß√£o r√°pida ou pergunte de novo!",
    "Quer mudar de assunto? S√≥ digitar ‚Äònovo tema‚Äô.",
    "Essa resposta te ajudou? Clique em üëç ou üëé."
]

def gerar_quick_replies(question, explicacao, history=None):
    return [
        "Quero um exemplo pr√°tico",
        "Me explique passo a passo",
        "Tenho uma d√∫vida sobre esse tema"
    ]

def resposta_link(titulo, url, icone="üìÑ"):
    return f"<br><a class='chip' href='{url}' target='_blank'>{icone} {titulo}</a>"

def resposta_link_externo(titulo, url, icone="üîó"):
    return f"<br><a class='chip' href='{url}' target='_blank'>{icone} {titulo}</a>"

def generate_answer(question, context="", history=None, tipo_de_prompt=None, is_first_question=True):
    snippet = ""
    
    saudacao = random.choice(GREETINGS) if is_first_question else ""
    fechamento = random.choice(CLOSINGS)

    prompt = f"""
    Voc√™ √© a professora Nanda Mac.ia, uma IA did√°tica que guia alunos m√©dicos pelo Curso Online Consult√≥rio High Ticket.

    ATEN√á√ÉO: Leia cuidadosamente o hist√≥rico da conversa antes de responder.
    - Se esta n√£o √© a primeira mensagem do aluno, N√ÉO use novamente sauda√ß√µes como "Oi, Doutor(a), tudo bem?" ou "Como posso ajudar?". V√° direto ao ponto.
    - Se na √∫ltima intera√ß√£o o aluno respondeu com afirma√ß√µes curtas como "sim", "claro", "vamos", "vamos l√°", "ok" ou algo semelhante, entenda imediatamente que ele quer continuar diretamente para a pr√≥xima aula. N√ÉO pergunte novamente se ele quer come√ßar ou continuar. Simplesmente prossiga ensinando diretamente o pr√≥ximo t√≥pico do curso.
    - Comporte-se como uma professora que j√° est√° no meio da aula, mantendo coer√™ncia absoluta com o que foi ensinado at√© agora, sem introdu√ß√µes desnecess√°rias ap√≥s o in√≠cio da conversa.

    Hist√≥rico anterior da conversa:
    {history}

    Mensagem atual do aluno:
    '{question}'

    Com base nisso, prossiga diretamente com a explica√ß√£o da pr√≥xima aula ou conte√∫do, mantendo uma comunica√ß√£o clara, direta, did√°tica e acolhedora.

    Use o conte√∫do abaixo como base adicional para sua resposta:
    {snippet}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Responda SEMPRE em portugu√™s do Brasil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=700
        )
    except OpenAIError:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Responda SEMPRE em portugu√™s do Brasil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=700
        )

    explicacao = response.choices[0].message.content.strip()
    quick_replies = gerar_quick_replies(question, explicacao, history)

    if saudacao:
        resposta = f"{saudacao}<br><br>{explicacao}<br><br>{fechamento}"
    else:
        resposta = f"{explicacao}<br><br>{fechamento}"

    return resposta, quick_replies


    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Responda SEMPRE em portugu√™s do Brasil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=700
        )
    except OpenAIError:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Responda SEMPRE em portugu√™s do Brasil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=700
        )

    explicacao = response.choices[0].message.content.strip()
    quick_replies = gerar_quick_replies(question, explicacao, history)
    resposta = f"{saudacao}<br><br>{explicacao}<br><br>{fechamento}"

    return resposta, quick_replies
