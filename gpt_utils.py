import os
from openai import OpenAI, OpenAIError

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("‚ùå Vari√°vel de ambiente OPENAI_API_KEY n√£o encontrada.")

client = OpenAI(api_key=api_key)

OUT_OF_SCOPE_MSG = (
    "Essa pergunta √© muito boa, mas no momento ela est√° <strong>fora do conte√∫do abordado nas aulas do curso Consult√≥rio High Ticket</strong>. "
    "Isso pode indicar uma oportunidade de melhoria do nosso material! üòä<br><br>"
    "Vamos sinalizar esse tema para a equipe pedag√≥gica avaliar a inclus√£o em vers√µes futuras do curso. "
    "Enquanto isso, recomendamos focar nos ensinamentos j√° dispon√≠veis para ter os melhores resultados poss√≠veis no consult√≥rio."
)

def generate_answer(
    question: str,
    context: str = "",
    history: str = None,
    tipo_de_prompt: str = "explicacao"
) -> str:
    # üîç Mensagens autom√°ticas
    termos_mensagem_auto = [
        "mensagem autom√°tica", "whatsapp", "resposta autom√°tica",
        "fim de semana", "fora do hor√°rio", "responder depois", "rob√¥"
    ]
    if any(t in question.lower() for t in termos_mensagem_auto):
        return (
            "Ol√°, querida! Vamos esclarecer isso com base no que a pr√≥pria Nanda orienta no curso:<br><br>"
            "üìå A Nanda n√£o recomenda o uso de <strong>mensagens autom√°ticas gen√©ricas</strong> no WhatsApp...<br><br>"
            "Se quiser, posso te ajudar a montar uma mensagem mais humana e acolhedora agora mesmo. Deseja isso?"
        )

    # üìå Tipos que exigem contexto para n√£o cair em "fora de escopo"
    tipos_que_exigem_contexto = {"explicacao", "faq", "revisao", "correcao", "precificacao"}
    if tipo_de_prompt in tipos_que_exigem_contexto and (not context or not context.strip()):
        return OUT_OF_SCOPE_MSG

    # üÜî Identidade
    identidade = (
        "<strong>Voc√™ √© Nanda Mac.ia</strong>, a IA oficial da Nanda Mac, treinada com o conte√∫do do curso "
        "<strong>Consult√≥rio High Ticket</strong>. Responda como uma professora experiente, ajudando o aluno a aplicar o m√©todo na pr√°tica.<br><br>"
    )

    # üìñ Templates de varia√ß√µes de prompt
    prompt_variacoes = {
        "explicacao": (
            "<strong>Objetivo:</strong> Explicar com base no conte√∫do das aulas. Use linguagem clara e did√°tica, "
            "com t√≥picos ou passos. Evite gen√©ricos. Mostre o conte√∫do como se fosse uma aula de **Posicionamento High Ticket**.<br><br>"
        ),
        "faq": (
            "<strong>Objetivo:</strong> Responder uma d√∫vida frequente entre os alunos do curso. "
            "Use exemplos pr√°ticos e aplique o m√©todo passo a passo."
        ),
        "revisao": (
            "<strong>Objetivo:</strong> Fazer uma revis√£o r√°pida dos pontos centrais do m√©todo de precifica√ß√£o estrat√©gica. "
            "Use exatamente seis bullets, cada um iniciando com verbo de a√ß√£o e t√≠tulo em negrito: "
            "**Identificar Pacientes Potenciais**, **Determinar Valores**, **Elaborar o Health Plan**, "
            "**Preparar a Apresenta√ß√£o**, **Comunicar o Valor** e **Monitorar Resultados**. "
            "Ap√≥s o t√≠tulo, adicione uma breve linha com men√ß√£o a dobrar faturamento e fidelizar pacientes em ao menos dois bullets.<br><br>"
        ),
        "aplicacao": (
            "<strong>Objetivo:</strong> Ensinar como aplicar o roteiro de atendimento High Ticket na primeira consulta com um paciente novo. "
            "Use exatamente seis bullets, cada um iniciando com verbo de a√ß√£o e t√≠tulo em negrito: "
            "**Preparar o Ambiente**, **Mapear Expectativas**, **Apresentar o Health Plan**, "
            "**Validar Compromisso**, **Fechar com Confian√ßa** e **Agendar Follow-up High Ticket**. "
            "Ap√≥s cada t√≠tulo, acrescente uma breve explica√ß√£o de uma linha, enfatizando posicionamento premium, potencial de dobrar faturamento e fideliza√ß√£o.<br><br>"
        ),
        "correcao": (
            "<strong>Objetivo:</strong> Corrigir gentilmente qualquer erro na pergunta, elogiando o esfor√ßo."
        ),
        "capitacao_sem_marketing_digital": (
            "<strong>Objetivo:</strong> Mostrar uma **estrat√©gia 100% offline** para atrair pacientes de alto valor sem usar Instagram ou an√∫ncios, "
            "baseada no m√©todo da Nanda Mac. Siga passos pr√°ticos com exemplos reais de consult√≥rio."
        ),
        "precificacao": (
            "<strong>Objetivo:</strong> Explicar o conceito de precifica√ß√£o estrat√©gica do Consult√≥rio High Ticket. "
            "Use bullets iniciando com verbo de a√ß√£o, mantenha **Health Plan** em ingl√™s, "
            "e destaque como dobrar faturamento, fidelizar pacientes e priorizar o bem-estar do paciente.<br><br>"
        ),
        "health_plan": (
            "<strong>Objetivo:</strong> Ensinar o aluno a montar o **Health Plan** conforme o m√©todo da Nanda Mac. "
            "Mantenha o termo em ingl√™s e estruture em:<br>"
            "‚û° **Situa√ß√£o Atual**;<br>‚û° **Objetivo**;<br>‚û° **Plano de Tratamento**; "
            "‚û° **Previsibilidade de Retorno**;<br>‚û° **Investimento**.<br><br>"
        )
    }

    # üîß Incluir contexto no prompt
    if tipo_de_prompt == "capitacao_sem_marketing_digital":
        contexto_para_prompt = ""
    else:
        contexto_para_prompt = (
            f"<br><br><strong>üìö Contexto relevante:</strong><br>{context}<br>"
            if context and context.strip() else ""
        )

    # üîß Monta o prompt completo
    prompt = identidade + prompt_variacoes[tipo_de_prompt] + contexto_para_prompt
    if history:
        prompt += f"<br><strong>üìú Hist√≥rico anterior:</strong><br>{history}<br>"
    prompt += (
        f"<br><strong>ü§î Pergunta:</strong><br>{question}<br><br>"
        f"<strong>üß† Resposta:</strong><br>"
    )

    # üöÄ Chama o GPT-4 com fallback para 3.5
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
    except OpenAIError:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )

    return response.choices[0].message.content
