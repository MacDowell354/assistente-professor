import os
import re
import random
from openai import OpenAI, OpenAIError

# Configurar seu arquivo de transcri√ß√µes
TRANSCRIPTS_PATH = os.path.join(os.path.dirname(__file__), "transcricoes.txt")

# Inst√¢ncia do cliente OpenAI
client = OpenAI()

# Mensagem padr√£o para temas n√£o encontrados
OUT_OF_SCOPE_MSG = (
    "Desculpe, ainda n√£o tenho informa√ß√µes suficientes sobre esse tema espec√≠fico do curso. "
    "Por favor, envie outra pergunta ou consulte o material da aula."
)

# Sauda√ß√µes e fechamentos para humanizar as respostas
GREETINGS = [
    "Ol√°, Doutor(a), seja muito bem-vindo(a)!",
    "Oi, Doutor(a), tudo bem? Como posso ajudar?",
    "Bem-vindo(a) de volta, Doutor(a)!",
    "Ol√°, Doutor(a)! Estou aqui para apoiar voc√™ no seu crescimento"
]

CLOSINGS = [
    "Se quiser um exemplo pr√°tico ou modelo, clique nos bot√µes abaixo.",
    "Tem outro desafio no seu consult√≥rio? Me conte ou clique em Novo Tema.",
    "Se quiser aprofundar, escolha uma op√ß√£o r√°pida ou pergunte de novo!",
    "Quer mudar de assunto? S√≥ digitar ‚Äònovo tema‚Äô.",
    "Essa resposta te ajudou? Clique em üëç ou üëé."
]

# Cumprimentos espec√≠ficos e respostas dedicadas
CUMPRIMENTOS_RESPOSTAS = {
    "bom dia": "Bom dia! Se quiser tirar d√∫vidas sobre o curso, √© s√≥ perguntar. Estou √† disposi√ß√£o.",
    "boa tarde": "Boa tarde! Se quiser tirar d√∫vidas sobre o curso, √© s√≥ perguntar. Estou √† disposi√ß√£o.",
    "boa noite": "Boa noite! Estou aqui para ajudar. Pode enviar sua d√∫vida quando quiser.",
    "oi": "Oi, Doutor(a)! üòä Seja bem-vindo(a)! Pode enviar sua d√∫vida quando quiser.",
    "ol√°": "Ol√°! Estou aqui para ajudar. Pode perguntar sobre Consult√≥rio High Ticket quando quiser!",
    "ola": "Ol√°! Estou aqui para ajudar. Pode perguntar sobre Consult√≥rio High Ticket quando quiser!",
    "tudo bem": "Tudo √≥timo por aqui! Se quiser perguntar algo sobre o curso, fique √† vontade.",
    "oi, tudo bem": "Oi, tudo bem! Se quiser tirar d√∫vidas, pode perguntar que estou √† disposi√ß√£o.",
    "e a√≠": "E a√≠! Se quiser tirar d√∫vidas sobre o curso, estou por aqui para te ajudar."
}

def is_greeting(question):
    pergunta = question.strip().lower()
    for c in CUMPRIMENTOS_RESPOSTAS.keys():
        if pergunta == c or pergunta.startswith(c):
            return c
    return None

def remove_greeting_from_question(question):
    """Remove cumprimento do in√≠cio da pergunta, se houver, para detectar d√∫vida real."""
    pergunta = question.strip().lower()
    for c in CUMPRIMENTOS_RESPOSTAS.keys():
        if pergunta.startswith(c):
            pergunta_sem_cumprimento = pergunta[len(c):].lstrip(" ,.!?;-")
            return pergunta_sem_cumprimento
    return pergunta

def normalize_text(text):
    """Normaliza texto para melhorar buscas: minusculas, sem acentos, sem caracteres especiais."""
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", "", text)
    return text

def search_transcripts_by_theme(theme):
    """Busca no arquivo de transcri√ß√µes o trecho que cont√©m o tema."""
    theme_norm = normalize_text(theme)
    if not os.path.exists(TRANSCRIPTS_PATH):
        return None

    with open(TRANSCRIPTS_PATH, "r", encoding="utf-8") as f:
        content = f.read()

    content_norm = normalize_text(content)
    pos = content_norm.find(theme_norm)
    if pos == -1:
        palavras = theme_norm.split()
        for palavra in palavras:
            pos = content_norm.find(palavra)
            if pos != -1:
                break
        else:
            return None

    start = max(0, pos - 500)
    end = min(len(content), pos + 500)
    snippet = content[start:end]
    return snippet.strip()

def gerar_quick_replies(question, explicacao):
    """Sugere quick replies (chips) para UX moderna, de acordo com o tema."""
    base_replies = ["Novo Tema", "Preciso de exemplo", "Modelo PDF"]
    replies = []
    q = question.lower()
    if "plano" in q or "plan" in q:
        replies += ["Ver Exemplo de Plano", "Modelo PDF"]
    if "acne" in q:
        replies += ["Exemplo para Acne", "Tratamento Oral", "Cuidados Di√°rios"]
    if not replies:
        replies = base_replies
    return list(dict.fromkeys(replies))[:3]  # Remove duplicatas e limita a 3

def generate_answer(question, context="", history=None, tipo_de_prompt=None, is_first_question=True):
    cumprimento_detectado = is_greeting(question)
    pergunta_limpa = remove_greeting_from_question(question)

    # Se, depois de remover o cumprimento, n√£o sobrou nada relevante, responda s√≥ ao cumprimento
    if cumprimento_detectado and not pergunta_limpa.strip():
        return CUMPRIMENTOS_RESPOSTAS[cumprimento_detectado], []

    mostrar_saudacao = is_first_question
    mostrar_pergunta_repetida = is_first_question

    saudacao = random.choice(GREETINGS) if mostrar_saudacao else ""
    fechamento = random.choice(CLOSINGS)

    snippet = search_transcripts_by_theme(pergunta_limpa if pergunta_limpa.strip() else question)
    pergunta_repetida = f"<strong>Sua pergunta:</strong> \"{question}\"<br><br>" if mostrar_pergunta_repetida else ""

    # Gera prompt considerando hist√≥rico de chat, se dispon√≠vel
    if history:
        prompt = (
            f"Voc√™ √© Nanda Mac.ia, professora do curso Consult√≥rio High Ticket.\n"
            f"Abaixo est√° a conversa at√© agora entre o aluno e a professora:\n\n"
            f"{history}\n\n"
            f"O aluno enviou agora:\n"
            f"'{question}'\n\n"
            "Continue a conversa considerando o contexto anterior. Se o aluno pedir mais detalhes, exemplos, ou disser 'mais espec√≠fico', aprofunde sobre o assunto que estavam conversando, sem mudar de tema e sem repetir tudo do zero."
            "\nSe for uma d√∫vida nova, responda normalmente."
            "\n[IMPORTANTE] Seja did√°tica, acolhedora e responda exatamente ao que o aluno pediu."
            "\nUtilize o conte√∫do abaixo como base para a resposta:\n"
            f"{snippet}\n"
        )
    else:
        prompt = (
            f"Voc√™ √© Nanda Mac.ia, professora do curso Consult√≥rio High Ticket.\n"
            f"O aluno fez a seguinte pergunta:\n\n"
            f"'{question}'\n\n"
            "Responda de forma extremamente objetiva e did√°tica, exatamente como faria numa aula particular.\n"
            "Forne√ßa uma resposta estruturada em t√≥picos numerados, utilizando exemplos pr√°ticos e claros.\n"
            "Use APENAS o conte√∫do fornecido abaixo como refer√™ncia e responda diretamente √† pergunta feita,\n"
            "sem introdu√ß√µes ou divaga√ß√µes gerais:\n\n"
            f"{snippet}\n\n"
            "[IMPORTANTE] Seja objetiva, acolhedora e responda EXCLUSIVAMENTE ao tema solicitado."
        )

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Responda SEMPRE em portugu√™s do Brasil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=500
        )
    except OpenAIError:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Responda SEMPRE em portugu√™s do Brasil."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=500
        )

    explicacao = response.choices[0].message.content.strip()
    quick_replies = gerar_quick_replies(question, explicacao)

    # S√≥ exibe sauda√ß√£o e pergunta na primeira intera√ß√£o
    resposta = ""
    if mostrar_saudacao:
        resposta += f"{saudacao}<br><br>{pergunta_repetida}{explicacao}<br><br>{fechamento}"
    else:
        resposta += f"{explicacao}<br><br>{fechamento}"

    return resposta, quick_replies
