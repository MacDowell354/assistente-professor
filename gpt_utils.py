import os
from openai import OpenAI

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ VariÃ¡vel de ambiente OPENAI_API_KEY nÃ£o encontrada.")

client = OpenAI(api_key=api_key)

def generate_answer(question: str, context: str = "", history: str = None, tipo_de_prompt: str = "explicacao") -> str:
    identidade = (
        "<strong>VocÃª Ã© Nanda Mac.ia</strong>, a inteligÃªncia artificial oficial da Nanda Mac. "
        "Faz parte da equipe de apoio da Nanda e foi treinada exclusivamente com o conteÃºdo do curso <strong>ConsultÃ³rio High Ticket</strong>. "
        "Seu papel Ã© ensinar, orientar e responder Ã s dÃºvidas dos alunos com clareza, objetividade e didatismo. "
        "Responda como se fosse uma professora experiente, ajudando o aluno a aplicar o mÃ©todo na prÃ¡tica. "
        "Nunca responda como se estivesse ajudando pacientes â€” apenas profissionais da saÃºde que estÃ£o aprendendo o conteÃºdo do curso.<br><br>"
    )

    prompt_variacoes = {
        "explicacao": "...",
        "faq": "...",
        "revisao": "...",
        "aplicacao": "...",
        "correcao": "...",
        "capitacao_sem_marketing_digital": "...",
        "precificacao": "...",
        "health_plan": "..."
    }

    # ğŸš« Fora do escopo se nÃ£o houver contexto
    if not context or context.strip() == "":
        return (
            "Essa pergunta Ã© muito boa, mas no momento ela estÃ¡ <strong>fora do conteÃºdo abordado nas aulas do curso ConsultÃ³rio High Ticket</strong>. "
            "Isso pode indicar uma oportunidade de melhoria do nosso material! ğŸ˜Š<br><br>"
            "Vamos sinalizar esse tema para a equipe pedagÃ³gica avaliar a inclusÃ£o em versÃµes futuras do curso. "
            "Enquanto isso, recomendamos focar nos ensinamentos jÃ¡ disponÃ­veis para ter os melhores resultados possÃ­veis no consultÃ³rio."
        )

    prompt = identidade + prompt_variacoes.get(tipo_de_prompt, "")

    if context:
        prompt += f"<br><br><strong>ğŸ“š Contexto relevante do curso:</strong><br>{context}<br>"

    if history:
        prompt += f"<br><strong>ğŸ“œ HistÃ³rico anterior:</strong><br>{history}<br>"

    prompt += f"<br><strong>ğŸ¤” Pergunta do aluno:</strong><br>{question}<br><br><strong>ğŸ§  Resposta:</strong><br>"

    # ğŸ” Define modelo baseado no tipo de prompt
    if tipo_de_prompt in ["health_plan", "aplicacao", "precificacao", "capitacao_sem_marketing_digital"]:
        modelo_escolhido = "gpt-4"
    else:
        modelo_escolhido = "gpt-3.5-turbo"

    response = client.chat.completions.create(
        model=modelo_escolhido,
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
